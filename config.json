{
    "CUDA": {
        "CUDA_VISIBLE_DEVICES" : "6"
    },
    "PATH": {
        "dataset_card"    : "Estwld/atomic2020-instruct",
        "dataset_path"    : "./dataset",
        "model_path"      : "/datas/huggingface/Flan-T5/flan-t5-small",
        "model_card"      : "google/flan-t5-xxl",
        "lora_model_path" : "./results/lora_flan-t5-small_2023_04_28_12",
        "output_path"     : "./results/eval",
        "log_path"        : "./log",
        "use_localdataset": false,
        "use_localmodel"  : true
    },
    "TRAIN": {
        "learning_rate"              : 5e-5,
        "evaluation_strategy"        : "no",
        "warmup_steps"               : 0.003,
        "fp16"                       : false,
        "bf16"                       : true,
        "tf32"                       : true,
        "weight_decay"               : 1e-4,
        "num_train_epochs"           : 5,
        "per_device_train_batch_size": 8,
        "per_device_eval_batch_size" : 64,
        "gradient_accumulation_steps": 4,
        "dataloader_num_workers"     : 4,
        "dataloader_pin_memory"      : true,
        "optim"                      : "adamw_torch",
        "load_best_model_at_end"     : false,
        "greater_is_better"          : true,
        "save_strategy"              : "epoch",
        "report_to"                  : "wandb",
        "logging_dir"                : "./logs",
        "logging_strategy"           : "steps",
        "logging_steps"              : 50,
        "seed"                       : 42,
        "resume_from_checkpoint"     : false,
        "auto_find_batch_size"       : false,
        "group_by_length"            : false,
        "run_name"                   : "test",
        "generation_max_length"      : 120
    },
    "LORA": {
        "do_lora"       : true,
        "load_in_8bit"  : false,
        "task_type"     : "SEQ_2_SEQ_LM",
        "target_modules": ["q", "v"],
        "r"             : 8,
        "lora_alpha"    : 16,
        "lora_dropout"  : 0.05
    },
    "GENERATE": {
        "num_beams"           : 5,
        "top_p"               : 0.95,
        "top_k"               : 50,
        "repetition_penalty"  : 2.5,
        "length_penalty"      : 1.0,
        "num_return_sequences": 1
    },
    "BACKUP": {
        "eval_steps": 1000
    }
}